# AI Art Image Classification  
**ECS 170 â€“ Introduction to Artificial Intelligence**  
_Fall 2024 â€¢ UC Davis_

## Team Members
Aaryan Mohta, Angela Lee, Gyeongseob Brian Lee, Jess Fong, Junhee Lee, Kaitlyn Vo, Lana Wong, **Stephanie Espinoza Gutierrez**

---

## ðŸ§  1. Introduction

AI continues to evolve rapidly, blurring the lines between human and machine creativity. With the rise of AI-generated art, questions of authenticity and authorship have become more urgent in artistic communities.

This project aims to train a convolutional neural network (CNN) model to classify whether a piece of artwork was created by a human or generated by AI. Using supervised machine learning and a labeled dataset, the model learns visual patterns to distinguish between the two.

---

## ðŸ“š 2. Background

We use the following machine learning techniques:

- **Supervised Learning**: A learning algorithm maps inputs to labeled outputs using example data.
- **Convolutional Neural Networks (CNNs)**: Deep learning models specialized for processing visual data.
- **Image Classification**: The task of assigning a category (human vs. AI) to an image input.

---

## âš™ï¸ 3. Methodology

### 3.1 Data Cleaning and Exploratory Data Analysis

We used two Kaggle datasets totaling **180,000+ images**, including:

- 60,000 human-drawn artworks (from ArtBench-10)
- 105,000 AI-generated images (via Latent and Standard Diffusion models)

Each image was resized to **224x224 pixels**, normalized, and assigned binary labels:  
`0` = AI-generated, `1` = human-created.

> To address **class imbalance**, we applied augmentation (rotation, flipping, zoom) to human-made images.

![Figure 1.1: Human-made Arts](./figures/Figure%201.1%20Human-made%20Arts.png)

![Figure 1.2: AI Generated Arts](./figures/Figure%201.2%20AI%20Generated%20Arts.png)

![Figure 2: Data Augmented Images](./figures/Figure%202%20Data%20Augmented%20Images.png)

---

### 3.2 CNN Model Selection and Training

We compared two models:

- **ResNet-50** (pretrained with ImageNet)
- **EfficientNetB0**

Training included:

- **Loss Function**: Binary cross-entropy  
- **Optimizer**: Adam (learning rate = 0.001)  
- **Regularization**: Dropout, batch normalization  
- **Early stopping** to reduce overfitting

We fine-tuned the last 10 layers of ResNet-50 with a lower learning rate to specialize it for our task.

![Figure 3: ResNet Model Architecture](./figures/Figure%203%20ResNet%20Model%20Architecture.png)

---

## ðŸ“Š 4. Results

### Model Performance

**ResNet-50** significantly outperformed EfficientNet:

- ResNet-50: ~**90% validation accuracy**
- EfficientNet: ~**57% validation accuracy**

![Figure 4: ResNet-50 Accuracy](./figures/Figure%204%20ResNet-50%20Model%20Train%20and%20Validation%20Accuracy%20Plots.png)

![Figure 5: EfficientNet Accuracy](./figures/Figure%205%20EfficientNet%20Model%20Train%20and%20Accuracy%20Plots.png)

### Confusion Matrix (ResNet-50)

Out of **30,000 test samples**:
- 17,608 AI images correctly classified
- 8,734 human artworks correctly classified

Overall accuracy: **~87.8%**

![Figure 6: Confusion Matrix](./figures/Figure%206%20Confusion%20Matrix.png)

---

## ðŸ’¬ 5. Discussion

Despite limited compute resources (frequent GPU disconnects), we achieved solid results using transfer learning.  
Key takeaways:

- **Data augmentation** is essential for balancing imbalanced datasets
- **ResNet-50** is highly effective for image classification tasks in resource-constrained environments
- **EfficientNet** underperformed, likely due to poor fit with our dataset's image characteristics

---

## âœ… 6. Conclusion

This project demonstrates how CNN-based models can effectively classify AI-generated art from human-created art.  
With ~90% accuracy, this tool can help artists, collectors, and platforms detect AI involvement and encourage transparency in digital art creation.

The project also raises important ethical questions about authorship, originality, and the future of art in the AI era.

---
